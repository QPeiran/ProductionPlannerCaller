{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1603943903180",
   "display_name": "Python 3.8.6 64-bit ('PlanningClient': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark Basic Operations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x2a5fff905e0>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.128.130.20:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Spark Basic Operations</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType,StructField,StringType,LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(name=\"city\", dataType=StringType(), nullable=True),\n",
    "        StructField(name=\"country\", dataType=StringType(), nullable=True),\n",
    "        StructField(name=\"counts\", dataType=LongType(),nullable=False)\n",
    "    ]\n",
    ") ## well..same as BigQuery.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    Row(\"Auckland\", \"New Zeland\", 10),\n",
    "    Row(\"Sydney\", \"Australia\", 53),\n",
    "    Row(\"Wellington\", \"New Zeland\", 5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelizeRows = spark.sparkContext.parallelize(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.rdd.RDD"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "type(parallelizeRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|  Auckland|New Zeland|    10|\n|    Sydney| Australia|    53|\n|Wellington|New Zeland|     5|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "df = spark.createDataFrame(parallelizeRows, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "type(df) # spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# If reading from a .csv format file\n",
    "# df = spark.read.csv()\n",
    "# For JSON \n",
    "# df = spark.read.json()\n",
    "# Create a lazy-view of spark dataframe\n",
    "df.createOrReplaceTempView('my_table')\n",
    "df_new = spark.sql(\"select * from my_table where city != 'Auckland'\") ## using spark sql\n",
    "type(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|    Sydney| Australia|    53|\n|Wellington|New Zeland|     5|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         city     country  counts\n0    Auckland  New Zeland      10\n1      Sydney   Australia      53\n2  Wellington  New Zeland       5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>country</th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Auckland</td>\n      <td>New Zeland</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sydney</td>\n      <td>Australia</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wellington</td>\n      <td>New Zeland</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# spark_dataframe => pandas_dataframe\n",
    "df_pandas = df.toPandas()\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some native spark_dataframe functions\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+\n|   country|\n+----------+\n|New Zeland|\n+----------+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "df.select(\"country\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+\n|   country|\n+----------+\n|New Zeland|\n+----------+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "df.select(F.col(\"country\")).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+--------+\n|   country|    city|\n+----------+--------+\n|New Zeland|Auckland|\n+----------+--------+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "df.select(\"country\", \"city\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+\n|destination|\n+-----------+\n| New Zeland|\n|  Australia|\n| New Zeland|\n+-----------+\n\n"
    }
   ],
   "source": [
    "df.select(F.expr(\"country AS destination\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------------+\n|country_again|\n+-------------+\n|   New Zeland|\n|    Australia|\n|   New Zeland|\n+-------------+\n\n"
    }
   ],
   "source": [
    "df.select(F.expr(\"country AS destination\").alias(\"country_again\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+----------+\n|new_country|   country|\n+-----------+----------+\n| New Zeland|New Zeland|\n|  Australia| Australia|\n| New Zeland|New Zeland|\n+-----------+----------+\n\n"
    }
   ],
   "source": [
    "df.selectExpr(\"country as new_country\", \"country\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+------------------+-----------------+\n|    average_counts|country_occurance|\n+------------------+-----------------+\n|22.666666666666668|                2|\n+------------------+-----------------+\n\n"
    }
   ],
   "source": [
    "df.selectExpr(\"avg(counts) AS average_counts\", \"count(distinct(country)) as country_occurance\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+---+\n|      city|   country|counts|One|\n+----------+----------+------+---+\n|  Auckland|New Zeland|    10|  1|\n|    Sydney| Australia|    53|  1|\n|Wellington|New Zeland|     5|  1|\n+----------+----------+------+---+\n\n"
    }
   ],
   "source": [
    "df.select(F.expr(\"*\"), F.lit(1).alias(\"One\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+---+\n|      city|   country|counts|one|\n+----------+----------+------+---+\n|  Auckland|New Zeland|    10|One|\n|    Sydney| Australia|    53|One|\n|Wellington|New Zeland|     5|One|\n+----------+----------+------+---+\n\n"
    }
   ],
   "source": [
    "df_more_column = df.withColumn(\"one\", F.lit(\"One\"))\n",
    "df_more_column.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+---+---+\n|      city|   country|counts|one|two|\n+----------+----------+------+---+---+\n|  Auckland|New Zeland|    10|One|  2|\n|    Sydney| Australia|    53|One|  2|\n|Wellington|New Zeland|     5|One|  2|\n+----------+----------+------+---+---+\n\n"
    }
   ],
   "source": [
    "# Renaming Column & change content\n",
    "df_more_column.withColumn(\"two\", F.expr(\"one\")).withColumn(\"two\", F.lit(2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+---+\n|      city|   country|counts|ONE|\n+----------+----------+------+---+\n|  Auckland|New Zeland|    10|One|\n|    Sydney| Australia|    53|One|\n|Wellington|New Zeland|     5|One|\n+----------+----------+------+---+\n\n"
    }
   ],
   "source": [
    "df_more_column.withColumnRenamed(\"one\",\"ONE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
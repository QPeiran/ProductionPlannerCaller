{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1604448193990",
   "display_name": "Python 3.8.6 64-bit ('PlanningClient': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark Basic Operations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x19f781ad490>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.128.130.98:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Spark Basic Operations</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType,StructField,StringType,LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(name=\"city\", dataType=StringType(), nullable=True),\n",
    "        StructField(name=\"country\", dataType=StringType(), nullable=True),\n",
    "        StructField(name=\"counts\", dataType=LongType(),nullable=False)\n",
    "    ]\n",
    ") ## well..same as BigQuery.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    Row(\"Auckland\", \"New Zeland\", 10),\n",
    "    Row(\"Sydney\", \"Australia\", 53),\n",
    "    Row(\"Wellington\", \"New Zeland\", 5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelizeRows = spark.sparkContext.parallelize(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.rdd.RDD"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "type(parallelizeRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|  Auckland|New Zeland|    10|\n|    Sydney| Australia|    53|\n|Wellington|New Zeland|     5|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "df = spark.createDataFrame(parallelizeRows, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "type(df) # spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.sql.dataframe.DataFrame"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# If reading from a .csv format file\n",
    "# df = spark.read.csv()\n",
    "# For JSON \n",
    "# df = spark.read.json()\n",
    "# Create a lazy-view of spark dataframe\n",
    "df.createOrReplaceTempView('my_table')\n",
    "df_new = spark.sql(\"select * from my_table where city != 'Auckland'\") ## using spark sql\n",
    "type(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|    Sydney| Australia|    53|\n|Wellington|New Zeland|     5|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         city     country  counts\n0    Auckland  New Zeland      10\n1      Sydney   Australia      53\n2  Wellington  New Zeland       5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>country</th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Auckland</td>\n      <td>New Zeland</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sydney</td>\n      <td>Australia</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wellington</td>\n      <td>New Zeland</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# spark_dataframe => pandas_dataframe\n",
    "df_pandas = df.toPandas()\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some native spark_dataframe functions\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Column<b'(NOT (city = Auckland))'>\nColumn<b'length(country)'>\n"
    }
   ],
   "source": [
    "# F actually is tranforming expr to sql\n",
    "# eg.\n",
    "print(F.col('city') != \"Auckland\")\n",
    "print(F.expr(\"length(country)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['city', 'country', 'counts']"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df.columns # type => list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+-----------+\n|      city|   country|counts|country_len|\n+----------+----------+------+-----------+\n|  Auckland|New Zeland|    10|         10|\n|    Sydney| Australia|    53|          9|\n|Wellington|New Zeland|     5|         10|\n+----------+----------+------+-----------+\n\n"
    }
   ],
   "source": [
    "df.withColumn('country_len', F.expr(\"length(country)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+\n|   country|\n+----------+\n|New Zeland|\n+----------+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "# select column by name\n",
    "df.select(\"country\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+\n|   country|\n+----------+\n|New Zeland|\n+----------+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "#also can be ref\n",
    "df.select(F.col(\"country\")).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+--------+\n|   country|    city|\n+----------+--------+\n|New Zeland|Auckland|\n+----------+--------+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "df.select(\"country\", \"city\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+\n|destination|\n+-----------+\n| New Zeland|\n|  Australia|\n| New Zeland|\n+-----------+\n\n"
    }
   ],
   "source": [
    "df.select(F.expr(\"country AS destination\")).show() # renaming method 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+\n|destination|\n+-----------+\n| New Zeland|\n|  Australia|\n| New Zeland|\n+-----------+\n\n"
    }
   ],
   "source": [
    "# df.select(F.expr(\"country AS destination\").alias(\"country_again\")).show()\n",
    "# .col is a simple expr, so it equal to\n",
    "df.select(F.col(\"country\").alias(\"destination\")).show() # renaming method 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+\n|destination|\n+-----------+\n| New Zeland|\n|  Australia|\n| New Zeland|\n+-----------+\n\n"
    }
   ],
   "source": [
    "df.select(\"country\").withColumnRenamed(\"country\", \"destination\").show() # renaming method 3/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+\n|   country|\n+----------+\n|NEW ZELAND|\n| AUSTRALIA|\n|NEW ZELAND|\n+----------+\n\n"
    }
   ],
   "source": [
    "# upper case\n",
    "df.select(\"country\").withColumn(\"country\", F.upper(F.col(\"country\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+----------+\n|new_country|   country|\n+-----------+----------+\n| New Zeland|New Zeland|\n|  Australia| Australia|\n| New Zeland|New Zeland|\n+-----------+----------+\n\n"
    }
   ],
   "source": [
    "df.selectExpr(\"country as new_country\", \"country\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+------------------+-----------------+\n|    average_counts|country_occurance|\n+------------------+-----------------+\n|22.666666666666668|                2|\n+------------------+-----------------+\n\n"
    }
   ],
   "source": [
    "df.selectExpr(\"avg(counts) AS average_counts\", \"count(distinct(country)) as country_occurance\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+---+\n|      city|   country|counts|One|\n+----------+----------+------+---+\n|  Auckland|New Zeland|    10|  1|\n|    Sydney| Australia|    53|  1|\n|Wellington|New Zeland|     5|  1|\n+----------+----------+------+---+\n\n"
    }
   ],
   "source": [
    "df.select(F.expr(\"*\"), F.lit(1).alias(\"One\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+---+\n|      city|   country|counts|one|\n+----------+----------+------+---+\n|  Auckland|New Zeland|    10|One|\n|    Sydney| Australia|    53|One|\n|Wellington|New Zeland|     5|One|\n+----------+----------+------+---+\n\n"
    }
   ],
   "source": [
    "df_more_column = df.withColumn(\"one\", F.lit(\"One\"))\n",
    "df_more_column.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+---+---+\n|      city|   country|counts|one|two|\n+----------+----------+------+---+---+\n|  Auckland|New Zeland|    10|One|  2|\n|    Sydney| Australia|    53|One|  2|\n|Wellington|New Zeland|     5|One|  2|\n+----------+----------+------+---+---+\n\n"
    }
   ],
   "source": [
    "# Renaming Column & change content\n",
    "df_more_column.withColumn(\"two\", F.expr(\"one\")).withColumn(\"two\", F.lit(2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+---+\n|      city|   country|counts|ONE|\n+----------+----------+------+---+\n|  Auckland|New Zeland|    10|One|\n|    Sydney| Australia|    53|One|\n|Wellington|New Zeland|     5|One|\n+----------+----------+------+---+\n\n"
    }
   ],
   "source": [
    "df_more_column.withColumnRenamed(\"one\",\"ONE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|  Auckland|New Zeland|    10|\n|    Sydney| Australia|    53|\n|Wellington|New Zeland|     5|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "# Removing\n",
    "df_old = df_more_column.drop('one')\n",
    "df_old.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+----------+------+\n|    city|   country|counts|\n+--------+----------+------+\n|Auckland|New Zeland|    10|\n+--------+----------+------+\n\n"
    }
   ],
   "source": [
    "# spark dataframe filtering\n",
    "df_old.filter((F.col(\"counts\") < 20) & (F.col(\"city\") == \"Auckland\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+----------+------+\n|    city|   country|counts|\n+--------+----------+------+\n|Auckland|New Zeland|    10|\n+--------+----------+------+\n\n"
    }
   ],
   "source": [
    "df_old.where(\"counts < 20 and city = 'Auckland'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+----------+------+\n|    city|   country|counts|\n+--------+----------+------+\n|Auckland|New Zeland|    10|\n+--------+----------+------+\n\n"
    }
   ],
   "source": [
    "df_old.filter(F.col(\"counts\") < 20).where(\"city = 'Auckland'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+\n|      city|\n+----------+\n|Wellington|\n|  Auckland|\n|    Sydney|\n+----------+\n\n"
    }
   ],
   "source": [
    "# select distinct\n",
    "df_old.select(\"city\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|Wellington|New Zeland|     5|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "df_old.sample(withReplacement=False, fraction=0.2, seed=7).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "488"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "df_test = spark.range(1000)\n",
    "df_test.sample(0.5).count()\n",
    "#    .. note:: This is not guaranteed to provide exactly the fraction specified of the total\n",
    "#        count of the given :class:`DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on method randomSplit in module pyspark.sql.dataframe:\n\nrandomSplit(weights, seed=None) method of pyspark.sql.dataframe.DataFrame instance\n    Randomly splits this :class:`DataFrame` with the provided weights.\n    \n    :param weights: list of doubles as weights with which to split the :class:`DataFrame`.\n        Weights will be normalized if they don't sum up to 1.0.\n    :param seed: The seed for sampling.\n    \n    >>> splits = df4.randomSplit([1.0, 2.0], 24)\n    >>> splits[0].count()\n    2\n    \n    >>> splits[1].count()\n    2\n    \n    .. versionadded:: 1.4\n\n"
    }
   ],
   "source": [
    "help(df_test.randomSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "387\n613\n"
    }
   ],
   "source": [
    "df_split_test = df_test.randomSplit([0.4, 0.6])\n",
    "print(df_split_test[0].count())\n",
    "print(df_split_test[1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|Wellington|New Zeland|     5|\n|  Auckland|New Zeland|    10|\n|    Sydney| Australia|    53|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "# Sorting\n",
    "df_old.sort(\"counts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|Wellington|New Zeland|     5|\n|  Auckland|New Zeland|    10|\n|    Sydney| Australia|    53|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "df_old.orderBy(\"counts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+----------+----------+------+\n|      city|   country|counts|\n+----------+----------+------+\n|    Sydney| Australia|    53|\n|  Auckland|New Zeland|    10|\n|Wellington|New Zeland|     5|\n+----------+----------+------+\n\n"
    }
   ],
   "source": [
    "df_old.orderBy(F.desc(\"counts\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on function expr in module pyspark.sql.functions:\n\nexpr(str)\n    Parses the expression string into the column that it represents\n    \n    >>> df.select(expr(\"length(name)\")).collect()\n    [Row(length(name)=5), Row(length(name)=3)]\n    \n    .. versionadded:: 1.5\n\n"
    }
   ],
   "source": [
    "help(F.expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+--------+----------+------+\n|    city|   country|counts|\n+--------+----------+------+\n|Auckland|New Zeland|    10|\n|  Sydney| Australia|    53|\n+--------+----------+------+\n\n"
    }
   ],
   "source": [
    "# limiting extract result\n",
    "df_old.limit(2).show()\n",
    "# this is faster than\n",
    "# df_old.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
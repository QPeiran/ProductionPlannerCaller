{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1604368681376",
   "display_name": "Python 3.8.6 64-bit ('PlanningClient': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql as ps\n",
    "from pyspark.sql import Row\n",
    "# import pyspark.types as T # <= wrong one\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x234c7c61970>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.128.130.98:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>TimeIntelli</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "spark = ps.SparkSession.builder.appName(\"TimeIntelli\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    Row('2020-01-03'),\n",
    "    Row('2020 01 13'),\n",
    "    Row('2020 Jan 18')\n",
    "]\n",
    "myrdd = spark.sparkContext.parallelize(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<Row('2020-01-03')>, <Row('2020 01 13')>, <Row('2020 Jan 18')>]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "myrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema = T.StructType(\n",
    "    [T.StructField(name=\"date_str\", dataType=T.StringType(), nullable=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+\n|   date_str|\n+-----------+\n| 2020-01-03|\n| 2020 01 13|\n|2020 Jan 18|\n+-----------+\n\n"
    }
   ],
   "source": [
    "df = spark.createDataFrame(myrdd, schema= mySchema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- date_str: string (nullable = true)\n\n"
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Column<b\"CASE WHEN (to_date(`date_str`, 'yyyy-MM-dd') IS NOT NULL) THEN to_date(`date_str`, 'yyyy-MM-dd') END\">"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "x = F.when(F.to_date(F.col('date_str'), \"yyyy-MM-dd\").isNotNull(), F.to_date(F.col('date_str'), \"yyyy-MM-dd\"))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.sql.column.Column"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+-----------+\n|   date_str|       date|\n+-----------+-----------+\n| 2020-01-03| 2020-01-03|\n| 2020 01 13|empty-value|\n|2020 Jan 18|empty-value|\n+-----------+-----------+\n\n"
    }
   ],
   "source": [
    "df.withColumn(\"date\", x.otherwise('empty-value')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df.withColumn(\"date & time\", F.when(F.to_timestamp(F.col('date_str'), \"yyyy-MM-dd\").isNotNull(), \n",
    "                                        F.to_timestamp(F.col('date_str'), \"yyyy-MM-dd\")\n",
    "                                        ).otherwise(F.when(F.to_timestamp(F.col('date_str'), \"yyyy MM dd\").isNotNull(), \n",
    "                                                    F.to_timestamp(F.col('date_str'), \"yyyy MM dd\")\n",
    "                                                        ).otherwise(F.when(F.to_timestamp(F.col('date_str'), \"yyyy MMM dd\").isNotNull(), \n",
    "                                                                            F.to_timestamp(F.col('date_str'), \"yyyy MMM dd\")\n",
    "                                                                            ).otherwise(F.to_timestamp(F.col('date_str'), \"MM dd yyyy\"))\n",
    "                                                                    )\n",
    "                                                    )\n",
    "                        )\n",
    "# giant shit-show, better to break up for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- date_str: string (nullable = true)\n |-- date & time: timestamp (nullable = true)\n\n"
    }
   ],
   "source": [
    "df_time.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_date = df_time.withColumn(\"date\", F.when(F.to_date(F.col('date_str'), \"yyyy-MM-dd\").isNotNull(), \n",
    "                                        F.to_date(F.col('date_str'), \"yyyy-MM-dd\")\n",
    "                                        ).otherwise(F.when(F.to_date(F.col('date_str'), \"yyyy MM dd\").isNotNull(), \n",
    "                                                    F.to_date(F.col('date_str'), \"yyyy MM dd\")\n",
    "                                                        ).otherwise(F.when(F.to_date(F.col('date_str'), \"yyyy MMM dd\").isNotNull(), \n",
    "                                                                            F.to_date(F.col('date_str'), \"yyyy MMM dd\")\n",
    "                                                                            ).otherwise(F.to_date(F.col('date_str'), \"MM dd yyyy\"))\n",
    "                                                                    )\n",
    "                                                    )\n",
    "                        )\n",
    "# giant shit-show, better to break up for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+-------------------+----------+\n|   date_str|        date & time|      date|\n+-----------+-------------------+----------+\n| 2020-01-03|2020-01-03 00:00:00|2020-01-03|\n| 2020 01 13|2020-01-13 00:00:00|2020-01-13|\n|2020 Jan 18|2020-01-18 00:00:00|2020-01-18|\n+-----------+-------------------+----------+\n\n"
    }
   ],
   "source": [
    "df_date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "root\n |-- date_str: string (nullable = true)\n |-- date & time: timestamp (nullable = true)\n |-- date: date (nullable = true)\n\n"
    }
   ],
   "source": [
    "df_date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+-------------------+----------+-----------+\n|   date_str|        date & time|      date|date_sub_10|\n+-----------+-------------------+----------+-----------+\n| 2020-01-03|2020-01-03 00:00:00|2020-01-03| 2019-12-24|\n| 2020 01 13|2020-01-13 00:00:00|2020-01-13| 2020-01-03|\n|2020 Jan 18|2020-01-18 00:00:00|2020-01-18| 2020-01-08|\n+-----------+-------------------+----------+-----------+\n\n"
    }
   ],
   "source": [
    "# date_sub function -- move date\n",
    "df_date.withColumn(\"date_sub_10\", F.date_sub(\"date\", 10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+-------------------+----------+-----------+\n|   date_str|        date & time|      date|date_add_10|\n+-----------+-------------------+----------+-----------+\n| 2020-01-03|2020-01-03 00:00:00|2020-01-03| 2020-01-23|\n| 2020 01 13|2020-01-13 00:00:00|2020-01-13| 2020-02-02|\n|2020 Jan 18|2020-01-18 00:00:00|2020-01-18| 2020-02-07|\n+-----------+-------------------+----------+-----------+\n\n"
    }
   ],
   "source": [
    "# date_add function -- move date\n",
    "df_date.withColumn(\"date_add_10\", F.date_add(\"date\", 20)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+-------------------+----------+---------+\n|   date_str|        date & time|      date|date_diff|\n+-----------+-------------------+----------+---------+\n| 2020-01-03|2020-01-03 00:00:00|2020-01-03|      306|\n| 2020 01 13|2020-01-13 00:00:00|2020-01-13|      296|\n|2020 Jan 18|2020-01-18 00:00:00|2020-01-18|      291|\n+-----------+-------------------+----------+---------+\n\n"
    }
   ],
   "source": [
    "# datediff function -- find the date fifference\n",
    "df_date.withColumn(\"date_diff\", F.datediff(F.current_date(), \"date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-----------+-------------------+----------+----+----+-------+\n|   date_str|        date & time|      date|year|week|weekday|\n+-----------+-------------------+----------+----+----+-------+\n| 2020-01-03|2020-01-03 00:00:00|2020-01-03|2020|   1|      6|\n| 2020 01 13|2020-01-13 00:00:00|2020-01-13|2020|   3|      2|\n|2020 Jan 18|2020-01-18 00:00:00|2020-01-18|2020|   3|      7|\n+-----------+-------------------+----------+----+----+-------+\n\n"
    }
   ],
   "source": [
    "df_date.withColumn('year', F.year('date')) \\\n",
    "       .withColumn('week', F.weekofyear('date')) \\\n",
    "       .withColumn('weekday', F.dayofweek('date')) \\\n",
    "       .show()\n",
    "# beware the week start from Sunday as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Column<b'(date > 2020-01-10)'>\n+-----------+-------------------+----------+\n|   date_str|        date & time|      date|\n+-----------+-------------------+----------+\n| 2020 01 13|2020-01-13 00:00:00|2020-01-13|\n|2020 Jan 18|2020-01-18 00:00:00|2020-01-18|\n+-----------+-------------------+----------+\n\n"
    }
   ],
   "source": [
    "# time intelligence filtering\n",
    "print(F.col(\"date\") > \"2020-01-10\") # => is first been trans to spark sql\n",
    "df_date.where(F.col(\"date\") > \"2020-01-10\").show()"
   ]
  }
 ]
}